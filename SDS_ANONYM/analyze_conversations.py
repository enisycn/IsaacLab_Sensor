#!/usr/bin/env python3
"""
Script to analyze agent conversation files and track environment analysis data flow
"""
import json
import os
import re
import sys
import glob

def analyze_conversation_file(filepath):
    """Analyze a single conversation file for environment analysis data"""
    try:
        with open(filepath, 'r') as f:
            conversation = json.load(f)
        
        env_data_found = {}
        agent_name = os.path.basename(filepath).replace('_conversation.json', '').replace('_conversation_READABLE.json', '')
        
        # Look for environment analysis data in all messages
        for message in conversation:
            content = message.get('content', '')
            if isinstance(content, list):
                # Handle list content format
                content = ' '.join([item.get('text', '') for item in content if item.get('type') == 'text'])
            
            # Search for environment data indicators
            env_indicators = {
                'gaps': [r'Total Gaps Detected:\s*(\d+)', r'Gaps Detected:\s*(\d+)\s*gaps'],
                'obstacles': [r'Total Obstacles Detected:\s*(\d+)', r'Obstacles Detected:\s*(\d+)\s*large obstacles'],
                'roughness': [r'Average Terrain Roughness:\s*([\d.]+)cm', r'Terrain Roughness:\s*([\d.]+)cm'],
                'safety': [r'Safety Score:\s*([\d.]+)%\s*traversable terrain']
            }
            
            for data_type, patterns in env_indicators.items():
                for pattern in patterns:
                    matches = re.findall(pattern, content)
                    if matches:
                        env_data_found[data_type] = matches[0]
                        break
        
        return agent_name, env_data_found
        
    except Exception as e:
        print(f"Error analyzing {filepath}: {e}")
        return None, {}

def main():
    print("üîç ANALYZING AGENT CONVERSATIONS FOR ENVIRONMENT ANALYSIS DATA")
    print("=" * 70)
    
    # Find all conversation files
    conversation_files = []
    
    # Check current directory
    conversation_files.extend(glob.glob("*_conversation*.json"))
    
    # Check outputs directory
    outputs_conversations = glob.glob("outputs/sds/*/.*_conversation*.json")
    conversation_files.extend(outputs_conversations)
    
    # Check Isaac Lab root
    isaaclab_conversations = glob.glob("/home/enis/IsaacLab/*_conversation*.json")
    conversation_files.extend(isaaclab_conversations)
    
    if not conversation_files:
        print("‚ùå No conversation files found!")
        print("Make sure to run the SDS process first to generate conversation files.")
        return
    
    print(f"üìÇ Found {len(conversation_files)} conversation files:")
    for f in conversation_files:
        print(f"  üìÑ {f}")
    print()
    
    # Analyze each conversation file
    agent_data = {}
    
    for conv_file in conversation_files:
        if '_READABLE' in conv_file:
            continue  # Skip readable versions, analyze raw JSON only
            
        agent_name, env_data = analyze_conversation_file(conv_file)
        if agent_name:
            agent_data[agent_name] = env_data
    
    # Print analysis results
    print("üìä ENVIRONMENT ANALYSIS DATA TRACKING:")
    print("-" * 50)
    
    agents_in_order = [
        'environmentawaretaskdescriptor',
        'enhancedssusgenerator', 
        'contactsequenceanalyser',
        'gaitanalyser',
        'taskrequirementanalyser'
    ]
    
    for agent in agents_in_order:
        if agent in agent_data:
            env_data = agent_data[agent]
            print(f"\nü§ñ {agent.upper()}:")
            
            if env_data:
                print(f"  ‚úÖ Environment data found:")
                for data_type, value in env_data.items():
                    print(f"    üìä {data_type}: {value}")
            else:
                print(f"  ‚ùå No environment analysis data found")
    
    # Check for data loss
    print(f"\nüîç DATA FLOW ANALYSIS:")
    print("-" * 30)
    
    task_descriptor_data = agent_data.get('environmentawaretaskdescriptor', {})
    sus_generator_data = agent_data.get('enhancedssusgenerator', {})
    
    if task_descriptor_data and not sus_generator_data:
        print("‚ùå PROBLEM: Environment data lost between TaskDescriptor ‚Üí SUSGenerator")
        print("   Check SUS generation prompt preservation instructions")
    elif not task_descriptor_data:
        print("‚ùå PROBLEM: Environment data not generated by TaskDescriptor")
        print("   Check environment analysis injection and prompt instructions")
    elif task_descriptor_data and sus_generator_data:
        print("‚úÖ GOOD: Environment data preserved through pipeline")
        
        # Compare values
        for data_type in ['gaps', 'obstacles', 'roughness', 'safety']:
            task_val = task_descriptor_data.get(data_type)
            sus_val = sus_generator_data.get(data_type)
            
            if task_val and sus_val:
                if task_val == sus_val:
                    print(f"  ‚úÖ {data_type}: preserved ({task_val})")
                else:
                    print(f"  ‚ö†Ô∏è {data_type}: changed from {task_val} to {sus_val}")
            elif task_val and not sus_val:
                print(f"  ‚ùå {data_type}: lost in SUS generation")
    
    print(f"\nüí° DEBUGGING TIPS:")
    print("-" * 20)
    print("1. Check the readable versions of conversation files:")
    for agent in agents_in_order:
        if agent in agent_data:
            print(f"   cat {agent}_conversation_READABLE.json")
    
    print("\n2. Look for these exact phrases in the conversations:")
    print("   - 'Total Gaps Detected: [NUMBER]'")
    print("   - 'Total Obstacles Detected: [NUMBER]'")
    print("   - 'Average Terrain Roughness: [NUMBER]cm'")
    print("   - 'Safety Score: [NUMBER]% traversable terrain'")

if __name__ == "__main__":
    main() 